\documentclass[a4paper,12pt,leqno]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage{amsmath}
\usepackage{a4wide}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{wrapfig}

\newcommand{\nel}[1]{|#1|}
\usepackage{program}

\title{\textbf{Algorytmy ewolucyjne}\\
       {\Large Raport z zadania pierwszego}\\[-1ex]}
\author{Karol Konaszyński i Wiktor Janas}
\date{Wrocław, dnia \today\ r.}

\newcommand{\avg}{\mathrm{avg}}
\newcommand{\dist}{\mathrm{dist}}
\newcommand{\median}{\mathrm{median}}
\newcommand{\target}{\mathrm{target}}
\newcommand{\RETURN}{|return|\ }

\begin{document}
\maketitle

Tematem tego projektu jest zastosowanie algorytmów ewolucyjnych do rozpoznawania obrazów. 
Problem rozpoznawania obrazów ma liczne zastosowania: od analizy zdjęć satelitarnych poprzez monitorowanie ruchu drogowego, po przemysł filmowy.
Z drugiej rozwiązanie go okazuje się być trudne, a pojęcie ,,podobieństwa obrazów'', oczywiste dla człowieka, nie jest precyzyjnie zdefiniowane.
Podejście zaproponowane w tej pracy polega na analizie samego kształtu obrazu, który uzyskujemy poprzez analizę jasności poszczególnych
pikseli (z pominięciem informacji o kolorze).

Przyjęliśmy następujące założenia: dana jest baza obrazów o zadanych nazwach (to znaczy, że wiemy, co one przedstawiają).
Każdy obraz, który chcemy rozpoznać (zapytanie) jest przyrównywane dp wszystkich obrazów z bazy.
Spośród obrazów bazowych wybieramy te, których odległość do zapytania jest najmniejsza.

\section{Znajdowanie punktów charakterystycznych}
Pierwszym etapem przetwarzania obrazu (pochodzącego z bazy danych lub będącego zapytaniem) jest znalezienie na nim punktów charakterystycznych.
Niech $\avg(x,y,d)$ oznacza średnią jasność obrazu w kwadracie o środku w $(x,y)$ i boku długości $d$. Dla piksela o współrzędnych $(x_0,y_0)$ oraz danej
wartości $d$ można zdefiniować funkcję
\[ F_d(\alpha) = \avg(x_0,y_0,d) - \avg( x_0+d\sin\alpha, y_0+d\cos\alpha, d) \]
Intuicyjnie jest to gradient piksela $(x_0,y_0)$ w kierunku $\alpha$ na obrazie zmniejszonym $d$-krotnie. Przyjmując kilka ustalonych wartości $d$
(w naszej implementacji były to $1,3,8$), można zdefiniować funkcję
\[ G(\alpha) = \sqrt[3]{F_1(\alpha) \cdot F_3(\alpha) \cdot F_8(\alpha)} \]
Następnie można obliczyć amplitudę tej funkcji:
\[ A = \max_\alpha G(\alpha) - \min_\alpha G(\alpha) \]
Wartość tą przyjmujemy za ,,miarę ciekawości'' piksela. 

Intuicja stojąca za tym algorytmem jest prosta -- szukamy punktów, w otoczeniu których następuje zmiana jasności obrazu. Miarą zmiany jasności w danym
kierunku jest gradient, zatem funkcja $F$ opisuje zmianę jasności obrazu we wszystkich kierunkach. Musimy jednak wziąć pod uwagę, że niektóre zmiany są
jedynie lokalne. Aby wyeleminować szum, obliczamy średnią geometryczbą funkcję $F$ dla kilku skal (jest to funkcja $G$) -- jeżeli istotnie zachodzi
rozpatrywany piksel leży w obszarze silnych zmian, nastąpi rezonans, gdy natomiast zmiana jest lokalna, funkcja większej skali ją ,,wyciszy''.
Według naszej całkowicie subiektywnej oceny skale 1,3,8 spradzają się najlepiej.

Mając określoną miarę ciekawości każdego piksela, chcemy wybrać określoną liczbę punktów charakterystycznych, które będą opisywały kształt obiektu
(liczba ta jest parametrem alogorytmu, najczęściej przyjmowaliśmy 50). Do tego celu zastosowaliśmy następujący algorytm: w każdym kolejnym kroku wybieramy
najciekawszy piksel na obrazku i dodajemy go do zbioru punktów interesujących. Nastepnie pewne jego otoczenie oznaczamy jako tabu i powtarzamy procedurę tak
długo, aż wszystkie punkty zostaną tabu. Aby określić wielkość tabu, zastosowaliśmy heurystykę ,,im ciekawiej tym gęściej''. Mianowicie, wielkość tabu jest
odwrotnie proporcjonalna do miary ciekawości punktu z pewnym współczynnikiem, który jest dobierany (za pomocą wyszukiwania binarnego) tak, aby ostateczny
zbiór punktów żądaną określoną wielkość. Proces wyszukiwania ciekawych punktów ilustruje rysunek \ref{poisrch}.

\begin{figure}\centering
\subfloat[gradient, $d = 1$]{\includegraphics[width=6cm,keepaspectratio=true]{./noisy-grad-1.png}}\hspace{5mm}
\subfloat[gradient, $d = 3$]{\includegraphics[width=6cm,keepaspectratio=true]{./noisy-grad-3.png}}\\
\subfloat[gradient, $d = 8$]{\includegraphics[width=6cm,keepaspectratio=true]{./noisy-grad-8.png}}\hspace{5mm}
\subfloat[gradient, łącznie]{\includegraphics[width=6cm,keepaspectratio=true]{./noisy-grad.png}}\\
\subfloat[znalezione punkty]{\includegraphics[width=6cm,keepaspectratio=true]{./noisy-pois.png}}
\caption{Proces wyszukiwania punktów charakterystycznych}\label{poisrch}
\end{figure}

\section{Analiza podobieństwa obrazów}

Mając określone punkty charakterystyczne, możemy zająć się badaniem podobienstwa obrazków.
Odległość od zbioru punktów $\bar P$ do zbioru $\bar Q$ definiujemy jako
\[ \dist(\bar P \rightarrow \bar Q) = \frac{1}{\nel{\bar P}} \cdot \sum_{p \in \bar P} \min_{q \in \bar Q}(\|p - q\|) \]
Odległość między zbiorami $\bar P$ a $\bar Q$ definiujemy jako
\[ \dist(\bar P, \bar Q) = \frac{\nel{\bar P} \cdot \dist(\bar P \rightarrow \bar Q) + \nel{\bar Q} \cdot \dist(\bar Q \rightarrow \bar P)}{\nel{\bar P} + \nel{\bar Q}} \]
Za miarę podobieństwa dwóch zbiorów punktów przyjmujemy
\[ \mathrm{similar}(\bar P, \bar Q) = \inf\{\dist(\bar P, M\bar Q) \;\arrowvert\; M\text{: afiniczne}\} \]
Jednak aby znaleźć tę musimy znaleźć przekształcenie minimalizujące wartość $\dist$. I tutaj wkracza ewolucja. 

\section{Ewolucja}

Naszymi osobnikami będą macierze afiniczne, czyli macierze postaci:
$\begin{pmatrix}
\star & \star & \star \\
\star & \star & \star \\
0 & 0 & 1
\end{pmatrix}$, gdzie drugi minor główny jest złożeniem obrotu i skalowania, natomiast ostatnia kolumna odpowiada za translację.
Funkcją celu jest zatem 
\[ \target = -\dist(\bar P,  M\bar Q) \]
gdzie $\bar P$ jest wektorem punktów charakterystycznych obrazka z zapytania, zaś $\bar Q$ -- wektorem tychże dla obrazka z bazy.
Celem ewolucji jest zmaksymalizowanie funkcji celu, czyli znalezienie przekształcenia minimalizującego odległość.

Do rozwiązania tego problemu wykorzystaliśmy ideę Differential Evolution. Pseudokod zaimplementowanego algorytmu przedstawiony został na listingu: 
\begin{program}
\FUNCT |evolve| \BODY
    P := \{\}
    \FOR i := 1 \TO N \DO
        P := P + |random_translation| * |random_rotation| * |random_scaling|
    \END
    \WHILE \NOT |termination_condition| \DO
        \FOR i := 1 \TO N \DO
            |evaluate|(P_i)
        \END
        |sort|(P) 
        ~
        P := \set{P_i | i \leq N*|replace\_rate| }
        \FOR i := 1 \TO N*|replace_rate| \DO
            \IF |random|(|de_prop|)
                \THEN P := P + |de_crossover|(P);
                \ELSE P := P + |roulette_selection|(P); \FI
        \END
        ~
        \FOR i := 1 \TO N \DO 
            \IF |random|(|t_prop|)
	        \THEN P_i := |random_translation| * P_i; \FI
            \IF |random|(|s_prop|)
                \THEN P_i := |random_scaling| * P_i; \FI
            \IF |random|(|r_prop|)
                \THEN P_i := |random_rotation| * P_i; \FI
	    \IF |random|(|f_prop|)
                \THEN P_i := |random_flip| * P_i; \FI
        \END
    \END
\END
~
\FUNCT |de_crossover|(P) \BODY
    x1 := |roulette_selection|(P)
    x2 := |roulette_selection|(P),\; x1 \neq x2
    x3 := |roulette_selection|(P),\; x3 \neq x1,\; x3 \geq x2
    \RETURN x1 + (x3-x2) * f_\text{de}
\END
~
\FUNCT |termination_condition| \BODY
    \RETURN |gen_idx| > G \OR 
	    |max_target|(|gen_idx|, |gen_idx|-K) \geq |max_target|(|gen_idx|-K, |gen_idx|-2*K)
\END
\end{program}

Najpierw odbywa się losowa inicjacja populacji z parametrem N. Następnie wchodzimy w pętlę ewolucji, która wykonuje się aż nie zostanie spełniony
warunek zakończenia. W pętli, pierwszą czynnością jest ewaluacja każdego osobnika, czyli znalezienie dla niego wartości target oraz fitness,
gdzie fitness jest współczynnikiem przystosowania:
\[ \mathrm{fitness}(p) = \frac{\target(p) - \min_{q \in P}\target(q)}{\sum_{r \in P} \target(r) - \min_{q \in P}\target(q)} \]
Wartość fitness jest wykorzystywana do uporządkowania osobników od najlepszego do najgorszego oraz podczas selekcji ruletkowej.
Potem następuje selekcja blokowa połączona z krzyżowaniem, ostatecznie zaś mutacja każdego osobnika. Warunkiem zakończenia ewolucji
jest przekroczenie pewnej ustalonej ilości pokoleń (zwykle rzędu 200) bądź stwierdzenie, że w czasie ostatnich $K$ pokoleń nie nastąpiła
poprawa w stosunku do poprzednich $K$ pokoleń ($K$ jest również parametrem).

Krzyżowanie polega na wybraniu metodą ruletki trzech różnych osobników $x_1, x_2, x_3$ a następnie utworzeniu z nich osobnika postaci
$x1 + f_\text{de}\cdot(x3-x2)$, gdzie $f_\text{de}$ jest parametrem, zaś operacja dodawania i mnożenia jest zwykłą operacją dodawania
macierzy i mnożenia ich przez skalar.

Ważną obserwacją którą poczyniliśmy jest to, że nie warto dokonywać losowych skalowań, czy obrotów wokół punktu $(0,0)$, gdyż to spowoduje duże
zmiany w położeniu punktów oddalonych od środka układu współrzędnych (czyli lewego górnego rogu). Aby tego uniknąć, obroty i skalowania wykonujemy
względem punktu wybranego z małego otoczenia punktu $(\median(\bar X), \median(\bar Y))$, gdzie $\bar X, \bar Y$ są zbiorami współrzędnych x, y
punktów charakterystycznych.

\begin{figure}\centering
\footnotesize\include{applemod-vs-fruits}\vspace{-2em}
\normalsize\caption{Dopasowanie owoców (\texttt{fruits}) do obróconego jabłka (\texttt{applemod}); uśrednione wyniki z dziesięciu uruchomień programu.}
\end{figure} 

\begin{figure}\centering
\footnotesize\include{square-vs-romb-popsize}\vspace{-2em}
\normalsize\caption{Wpływ rozmiaru populacji na ewolucję (dopasowanie \texttt{square} do \texttt{romb}); uśrednione wyniki z dziesięciu uruchomień programu.}
\end{figure}
\begin{figure}\centering
\footnotesize\include{square-vs-romb-deprop}\vspace{-2em}
\normalsize\caption{Wpływ prawdopodobieństwa krzyżowania na ewolucję (dopasowanie \texttt{square} do \texttt{romb}); uśrednione wyniki dziesięciu uruchomień programu.}
\end{figure}
\begin{figure}\centering
\footnotesize\include{square-vs-romb-surv}\vspace{-2em}
\normalsize\caption{Wpływ współczynnika przetrwania na ewolucję (dopasowanie \texttt{square} do \texttt{romb}); uśrednione wyniki dziesięciu uruchomień programu.}
\end{figure}

\begin{figure}\centering
\includegraphics[width=6cm,keepaspectratio=true]{./cherries-match.png}
\caption{Dopasowanie \texttt{cherries} do \texttt{cherries6}}
\end{figure}


\begin{figure}\centering
\subfloat[Jabłko]{\includegraphics[width=5cm,keepaspectratio=true]{./apple-mod-pois.png}}
\subfloat[Wisienki]{\includegraphics[width=5cm,keepaspectratio=true]{./cherries-pois.png}}
\subfloat[Trójliterówka]{\includegraphics[width=5cm,keepaspectratio=true]{./jeb-pois.png}}
\caption{Wybrane obrazy testowe}
\end{figure}

\end{document}
