\documentclass[a4paper,12pt,leqno]{article}
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage[polish]{babel}
\usepackage{amsmath}
\usepackage{a4wide}
\usepackage{graphicx}
\usepackage{subfig}
\usepackage{wrapfig}

\newcommand{\nel}[1]{|#1|}

\usepackage{program}

\title{\textbf{Algorytmy ewolucyjne}\\
       {\Large Raport z zadania pierwszego}\\[-1ex]}
\author{Karol Konaszyński i Wiktor Janas}
\date{Wrocław, dnia \today\ r.}

\begin{document}
\maketitle

Niniejszy projekt jest kontynuacją pracy dotyczącej rozpoznawania obrazów. Wówczas udało nam się osiągnąć dobre wyniki, jeśli chodzi o odróżnianie figur geometrycznych i cyfr, a także bardziej
skomplikowanych obrazków, takich jak krótkie słowa i owoce. Wadą dotychczasowego algorytmu był przede wszystkim znaczny czas działania.

Ten projekt rozszerza dotychczasowe podejście w dwóch kierunkach. Po pierwsze, postanowiliśmy przyspieszyć program tak, aby osiągnąć wydajność dającą nadzieje na zastosowania praktyczne.
Po drugie, staraliśmy się uogólnić algorytm tak, aby był zdolny do rozpoznawania fragmentów obrazów, czyli znajdowania znanych obiektów z bazy na mozaikach.

W wyniku realizacji projektu powstały dwa programy. Jeden jest ograniczony do rozpoznawania pojedyńczych obrazów tak, jak było to w poprzedniej części projektu, zawiera jednak znaczne
usprawnienia wydajnościowe. Drugi program jest rozszerzony o rozpoznawanie mozaik, kosztem istotnie większego czasu działania.

\section{Przyspieszanie dopasowywania obrazów}

\section{Zmienne parametry ewolucji}

\section{Prace nad mozaikami}

Przez \textit{mozaikę} rozumiemy obrazek będący sklejeniem kilku (najczęściej czterech) obrazów podstawowych (patrz rys. \ref{mosaic}).
Naszym celem jest rozpoznanie obrazków składowych takiej mozaiki, czyli dopasowanie obrazków z bazy danych do fragmentu zapytania.
Niestety, algorytm badany w pierwszej części projektu nie działał dla takich testów.

Podstawowym problemem, jaki musieliśmy rozwiązać, jest skalowanie zbioru punktów charakterystycznych. 
Poprzednio bowiem rozmiar tego zbioru wybierany był ,,na sztywno'', przed wykonaniem jakichkolwiek przekształceń. Niestety, skutkiem tego była niewspółmierna gęstość POI. Jako, że mozaika
zawiera cztery obrazy, zawiera również cztery razy więcej szczegółów, czyli punktów charakterystycznych. Ustalenie rozmiaru zbioru POI na sztywno powodowało, że POI mozaiki
były rozmieszczone dużo rzadziej, niż POI obrazu z bazy. Jednocześnie osobniki, które starają się dopasować obraz z bazy poprzez zmniejszenie go, bardzo mocno zagęszczają POI.
Co gorsza, efekty te kumulują się: rozrzedzenie POI zapytania i zagęszczenie POI obrazka z bazy powoduje, że dopasowanie obrazów nastręcza znaczne trudności.

Zastosowane rozwiązanie wydaje się być dość naturalne. Zmodyfikowaliśmy algorytm wyszukiwania punktów charakterystycznych tak, aby najpierw wyszukiwał pewną z góry zadaną ilość POI na 
obrazku z zapytania; następnie dla przekształconych obrazów z bazy odpowiadających poszczególnym osobnikiom wybieramy zbiór POI tak, aby ich gęstość była podobna do gęstości punktów w 
zapytaniu. Niestety, algorytm wyszukujący punkty charakterystyczne na obrazie jest mało wydajny. Na szczęście działa on w dwóch fazach. Główny koszt obliczeniowy wiąże się z 
określeniem ,,ciekawości'' każdego piksela. Następnie względnie szybko daje się wybrać pewną ilość najlepszych pikseli, dbając o to, aby nie były one zbyt blisko siebie (parametr decydujący o
dopuszczalnej gęstości POI nazywa się \textit{tabu}). Po modyfikacjach algorytm działa następująco:
\begin{enumerate}
 \item oblicz ,,ciekawość'' dla każdego piksela obrazka z zapytania oraz wybierz wiele (około tysiąca) najciekawszych punktów.
 \item przefiltruj wybrane punkty tak, aby pozostała ich rozsądna ilość (80 -- 150).
 \item oblicz ,,ciekawość'' dla każdego piksela obrazka z bazy oraz wybierz wiele (około tysiąca) najciekawszych punktów.
 \item podczas ewaluacji osobnika, przekształć punkty wybrane w kroku 3 używając macierzy osobnika;
       następnie z otrzymanego zbioru wybierz punkty tak, aby ich gęstość odpowiadała gęstości punktów wybranych w kroku 2
\end{enumerate}

Powyższe rozwiązanie okazało się mieć wady i zalety. Podstawową wadą jest trywialne maksimum globalne funkcji celu. Jeżeli bowiem ściśnie się obrazek z bazy danych, wszystkie punkty wybrane
w kroku 3 przejdą na bardzo niewielki obszar; następnie filtrowanie z kroku 4 pozostawi jeden lub dwa punkty. W takim przypadku wystarczy, że punkty te znajdą się niedaleko jakiegokolwiek
POI zapytania. Efekt ten zmusił skłonił nas do sformułowania bardziej wyrafinowanego pojęcia ,,podobieństwa''. 

\subsection{Podobieństwo: definicja}
Dwa obrazki $O_1$, $O_2$ są podobne, jeżeli istnieje przekształcenie afiniczne $F$, dla którego odległość POI obrazków $O_1$, $F(O_2)$ jest relatywnie mała.
Ponadto wymagamy, aby $F$ oraz $F^{-1}$ skalowały co najwyżej czterokrotnie oraz ściskały conajwyżej dwukrotnie, gdzie skalowanie definiujemy jako
\[ s_f = \max_{\vec x \in R^2} \| f(\vec x) \| / \| \vec x \| \]
zaś ściskanie jako
\[ c_f = \max_{\vec x, \vec y \in R^2, \vec x \bot \vec y} \| f(\vec x) \| / \| f(\vec y) \| \]
W definicji pozostaje jeszcze jedna rzecz nieuściślona -- jest nią pojęcie odległości POI dwóch obrazków. Pamiętając o tym, że traktujemy POI obrazka jako zbiór (równorzędnych) punktów, 
musimy określić (asymetryczną) funkcję odległości jednego zbioru punktów od drugiego.
W dalszym ciągu umawiamy się, że liczymy odległość punktów z obrazka bazowego do obrazka z zapytania.

Do tej pory ogólnym schematem było znalezienie dla każdego punktu z bazowego najbliższy mu punkt w zapytaniu, a następnie policzenie odległości między nimi.
Wówczas odległość zbiorów była średnią odległością opisaną powyżej.
Należy jednak określić kilka rzeczy precyzyjniej, gdyż powyższy schemat okazał się niewystarczający.

W tym zadaniu leży spora trudność, trzeba bowiem pokonać kilka przeszkód.

\subsection{Problemy związane z nowym algorytmem}
\paragraph{przeszkoda 1: wiele do jednego}
Ponieważ punkty mają ustaloną gęstość, od ,,bliskich'' sobie obrazków oczekujemy, by ich punkty dopasowywały się ,,1-1''. 
Zatem nie chcemy, by do jednego punktu z zapytania dopasowywanych było wiele punktów bazowych. 

Dobrym rozwiązaniem tej kwestii okazało się policzenie, dla każdego punktu z zapytania, ile punktów bazowych wskazało go jako swojego najbliższego sąsiada. 
Z tak otrzymanego zbioru liczb naturalnych, liczymy średnią \textbf{niezerowych} wartości, otrzymując liczbę $W$.
Następnie przemnażamy odległość przez $e^{W-1}$. W ten sposób osobniki, które chciały ,,oszukać'', czyli dopasować kilka swoich POI do jednego, dostają za to wysoką karę.


\paragraph{przeszkoda 2: małe jest lepsze}
Dość intuicyjnym faktem jest to, że osobniki, których przekształcenie mocniej ściska obrazek, okazują się być średnio lepsze. Wynika to stąd, że im mniejszy obrazek, 
tym łatwiej dopasować go (całkowicie błędnie) do fragmentu czegoś dużego. 

Na szczęście rozwiązanie znalazło się trywialne -- wystarczy podzielić odległość przez rozpiętość obrazka. Wówczas osobniki o przekształceniach z wyższą skalą dostają rekompensatę.
Teraz z kolei nasuwa się pytanie o słowo ,,rozpiętość''. Ponieważ jest to całkowita heurystyka, wystarczającym okazało się wyznaczenie prostokąta zawierającego wszystkie punkty 
obrazka bazowego po przekształceniu, a następnie policzeniu długości jego przekątnej.

\paragraph{przeszkoda 3: bagatelizacja dużych błędów}
Oczywistym jest, że w przypadku nawet niemal identycznych obrazków, ich POI nie będą idealnie się pokrywały. Wynika to z charakterystyki ich wyboru; dopuszczalne jest, by były oddalone
o odległość o rzędzie wielkości podobnym do odległości między POI na jednym obrazku (czyli mniej więcej średnia wielkość tabu). 
Bardzo dobrym rozwiązaniem okazało się wprowadzenie niejednorodnej funkcji odległości -- jeżeli odległość POI bazowego od najbliższego mu POI z zapytania nie przekracza średniego ,,zasięgu''
POI, funkcja jest liniowa, jeżeli zaś przekracza -- sześcienna.
Formalniej, niech $\mathrm{avg}_t$ będzie średnią najkrótszą odległością między POI obrazka z zapytania, zaś $d_0$ realną odległością euklidesową POI dla których chcemy policzyć ,,ulepszoną'' odległość.
Wówczas odległość użyta do obliczania funkcji celu wyraża się wzorem:
\[ d_r = \begin{cases}
	    d_0 & \text{jeżeli } d_0 < \mathrm{avg}_t / 2 \\
	    d_0^3 / 4\mathrm{avg}_t^2 & \text{w przeciwnym wypadku}
	 \end{cases} \]
Skalowanie tej wartości o kwadrat $\mathrm{avg}_t$ ma na celu uciąglenie funkcji.

\paragraph{przeszkoda 4: im gęściej, tym łatwiej coś dla siebie znaleźć}
To jest główny mankament algorytmu. Jeżeli mozaika z zapytania składa się z obrazków istotnie różniących się skupieniem POI 
(na przykład większego i mniejszego lub bardziej kanciastego oraz mniej), mamy znacznie większą szansę, że obrazek bazowy dopasuje się do pewnych punktów z fragmentu, 
na którym ich jest po prostu więcej w jednym miejscu.

Pojawiło się kilka pomysłów na zapobieżenie tego problemu. Podstawowym z nich był powrót do koncepcji symetrycznej odległości, czyli sumy odległości jednego od drugiego oraz w drugą stronę.
Oczywiście, nie możemy zrobić tego tak jak wcześniej, gdyż punktów spoza interesującego nas fragmentu nie mamy zamiaru dopasowywać nigdzie -- powinny zostać niewykorzystane.
Tak więc naturalnym jest, by wziąć tylko te punkty z zapytania, które leżą ,,pod'' prostokątem rozpinanym przez POI z obrazka bazowego. Niestety, to rozwiązanie okazało się nie dawać 
oczekiwanych rezultatów.

Problem pozostał niestety nierozwiązany, jednak nie występuje w przypadku prostych testów.

\subsection{Zastosowanie wspomnianych pomysłów w praktyce}
\paragraph{wpływ ulepszeń na wyniki}
Dzięki powyższym ulepszeniom udało się zmusić nasz algorytm do działania na niektórych, prostszych, mozaikach. W szczególności, działają mozaiki złożone z prostych figur geometrycznych




\end{document}
